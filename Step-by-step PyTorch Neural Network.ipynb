{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtzLcD3mEzkIe7JQAUVd9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangou888/NN/blob/main/Step-by-step%20PyTorch%20Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step-by-step PyTorch Neural Network (Colab-Ready)\n",
        "\n",
        "## What This Code Does:\n",
        "1. Downloads and loads MNIST handwritten digit data.\n",
        "\n",
        "2. Builds a simple feedforward neural network with 2 hidden layers.\n",
        "\n",
        "3. Trains the model using SGD and CrossEntropyLoss.\n",
        "\n",
        "4. Evaluates test accuracy."
      ],
      "metadata": {
        "id": "23TZsKHvJcYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LP9MTq6rJPXE"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install dependencies (if not already in Colab)\n",
        "# Uncomment the line below if you're running outside Colab\n",
        "# !pip install torch torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Set up device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jiKxvJNKfU_",
        "outputId": "b94d23f2-b62a-4594-e0ae-4f12ba88761d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define the Neural Network Model\n",
        "class SimpleNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)  # First hidden layer (128 features)\n",
        "        self.fc2 = nn.Linear(128, 64)     # Second hidden layer (simplify to 64)\n",
        "        self.fc3 = nn.Linear(64, 10)      # Output layer (10 classes for digits)\n",
        "\n",
        "    # forward propagation\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)    # Flatten the image (-1 lets PyTorch infer the batch size)\n",
        "        x = F.relu(self.fc1(x))  # Apply ReLU activation to the first hidden layer\n",
        "        x = F.relu(self.fc2(x))  # Same as above, but now goes from 128 → 64 neurons\n",
        "        return self.fc3(x)       # Last layer: Linear(64 → 10)"
      ],
      "metadata": {
        "id": "DBd3H182KiXz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Summary:\n",
        "Name: MNIST (Modified National Institute of Standards and Technology)\n",
        "\n",
        "Content: 28x28 grayscale images of handwritten digits (0–9)\n",
        "\n",
        "Size:\n",
        "\n",
        "60,000 training images\n",
        "\n",
        "10,000 test images"
      ],
      "metadata": {
        "id": "B8YZPPScPZTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load MNIST Data\n",
        "transform = transforms.ToTensor()\n",
        "# from 60,000 training images\n",
        "train_data = datasets.MNIST(root='mnist_data', train=True, download=True, transform=transform)\n",
        "# from  10,000 test images\n",
        "test_data = datasets.MNIST(root='mnist_data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True) #  give you 64 images at a time (instead of one-by-one).\n",
        "test_loader = DataLoader(test_data, batch_size=1000)"
      ],
      "metadata": {
        "id": "6yyqUoiDLh6W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Initialize Model, Loss, Optimizer\n",
        "model = SimpleNet().to(device)\n",
        "# This is your loss function, which measures how far off your model’s predictions are.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# This sets up the optimizer, which updates model weights based on the loss.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # SGD: Stochastic Gradient Descent\n"
      ],
      "metadata": {
        "id": "S9TOwrcTLkeO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Training Loop\n",
        "epochs = 5  # Number of times to loop over the entire training dataset\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode (enables dropout, batchnorm if used)\n",
        "\n",
        "    total_loss = 0  # Keep track of total loss for this epoch\n",
        "\n",
        "    # Loop over batches of data from the training set\n",
        "    for images, labels in train_loader:\n",
        "        # Move data and labels to the same device as the model (CPU or GPU)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Step 1: Clear previous gradients from the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Step 2: Forward pass - compute predictions from the model\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Step 3: Compute the loss between predictions and actual labels\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Step 4: Backward pass - compute gradients of loss w.r.t. model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Step 5: Optimizer step - update model parameters based on gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss for monitoring\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Optional: Print epoch summary\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIDNIKh4LrQV",
        "outputId": "a5f1c9d1-1ed5-45d4-9d88-75c081c6801b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Training Loss: 501.3445\n",
            "Epoch 2/5, Training Loss: 185.3148\n",
            "Epoch 3/5, Training Loss: 126.6223\n",
            "Epoch 4/5, Training Loss: 94.1768\n",
            "Epoch 5/5, Training Loss: 76.5716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluation\n",
        "model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
        "correct = 0   # Counter for correct predictions\n",
        "total = 0     # Counter for total predictions\n",
        "all_preds = []\n",
        "all_images = []\n",
        "\n",
        "# No need to compute gradients when evaluating (save momery)\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move test data to the same device as the model (CPU or GPU)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass: get predicted outputs from the model\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Get the predicted class by taking the index with the highest score\n",
        "        # torch.max return:\n",
        "        # 1. The maximum value in each row (i.e., the actual score/logit)\n",
        "        # 2. The index of the maximum value (i.e., the predicted class)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Count total number of predictions\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Count number of correct predictions\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_images.extend(images.cpu().numpy())\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHCnJJEALvCO",
        "outputId": "757104bf-2d17-4936-ef08-5eaedf15c1aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Save the model (saving the trained model’s parameters (weights and biases))\n",
        "torch.save(model.state_dict(), \"mnist_cnn.pth\")\n",
        "print(\"Model saved as mnist_cnn.pth\") # .pth is a common extension in PyTorch (but you can name it anything)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QhcVozSMHVF",
        "outputId": "8a3fc69e-e2c1-46a6-bbe9-48a72e85d00c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as mnist_cnn.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Load the model (example)\n",
        "# Improves accuracy by using convolution and pooling\n",
        "model_loaded = SimpleNet().to(device)\n",
        "model_loaded.load_state_dict(torch.load(\"mnist_cnn.pth\"))\n",
        "model_loaded.eval()\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSUadBz5MJ4T",
        "outputId": "7a49890f-b77e-450d-af14-24e290fbfd33"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Show sample predictions\n",
        "def show_predictions(images, preds, n=6):\n",
        "    plt.figure(figsize=(12, 2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
        "        plt.title(f\"Pred: {preds[i]}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_predictions(all_images, all_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "3KwshZ9uMLyC",
        "outputId": "da7afe79-01c1-4e59-8225-c8833f65ab56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-17-1638934438.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mshow_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'all_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RAUbfmYfMO-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LFigXgEeJWwd"
      }
    }
  ]
}